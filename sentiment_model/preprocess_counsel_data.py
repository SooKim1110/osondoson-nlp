# -*- coding: utf-8 -*-
"""preprocess_1388.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_wH5r-mgakEVE349rTY5ei21B8OW9faR
"""

import pandas as pd

from google.colab import drive

# 구글 드라이브에서 데이터 로드
drive.mount('/content/drive', force_remount=True)

# df = pd.read_excel("/content/drive/My Drive/Colab Notebooks/대화_연속적.xlsx")
# df = df[['Sentence','Emotion']]
# df = df[df['Emotion'] == '행복']
# df.to_excel('연속적_행복.xlsx')

data = pd.read_csv("/content/drive/My Drive/Colab Notebooks/crawl.csv")

data = pd.read_excel("/content/drive/My Drive/Colab Notebooks/감정_문장별.xlsx")
data

import re 
def preprocess_text(sentence):
  re_pattern = r'\r'
  new_text = re.sub(re_pattern, '', sentence)
  re_pattern = r'\n'
  new_text = re.sub(re_pattern, '', new_text)
  re_pattern = r'\t'
  new_text = re.sub(re_pattern, '', new_text)
  return new_text


data.iloc[:,0] = data.iloc[:,0].apply(preprocess_text)
data.iloc[:,1] = data.iloc[:,1].apply(preprocess_text)

data = data.set_axis(['고민','답변'], axis=1, inplace=False)
data

pd.set_option('display.max_colwidth',1000)

# 고민 내용 전처리
def pre_text(sentence):
  re_pattern = r'고민상담게시판'
  new_text = re.sub(re_pattern, '', sentence)
  re_pattern = r'제목'
  new_text = re.sub(re_pattern, '', new_text)
  return new_text

data.iloc[:,0] = data.iloc[:,0].apply(pre_text)
data

# 답변 내용 전처리

answer = []
for idx, sentence in enumerate(data['답변']):
  info = sentence.split('작성자 ')
  info.pop(0) #첫 element 삭제
  info2 = []
  if len(info) > 1:
    st = info[0]
    s = info[0]
    for i in range(len(info)-1):
      if (st[3] == info[i+1][3]):
        s+= info[i+1]
      else:
        info2.append(s)
        st = info[i+1]
        s = info[i+1]
    if s != "":
      info2.append(s)
  answer.append(info2)

answer[0]

# 게시글의 답변 개수 보기 
len_list = [0 for i in range(26)]
for idx,x in enumerate(answer):
  len_list[len(x)] += 1

for idx, x in enumerate(len_list):
  print(idx , " " , x)

#answer애서 컴슬러 이름, 시간 지우기 
def pre_text(sentence):
  re_pattern = r'컴슬러[A-Z] \((\d{4})-(\d{2})-(\d{2}) (\d{2}):(\d{2}):(\d{2})\)'
  new_text = re.sub(re_pattern, '', sentence)
  return new_text

for idx1, x in enumerate(answer):
  for idx2, sent in enumerate(x):
    answer[idx1][idx2] = pre_text(sent)


answer = answer

answer[0]

# 데이터 분리
title = []
user = []
date = []
text = []

for sentence in data['고민']:
  info = sentence.split('작성자',1)
  title.append(info[0])
  info2 = info[1].split('작성일',1)
  user.append(info2[0])
  string = (info2[1])
  date.append(string[:10])
  text.append(string[10:])

# dict = {'title': title, 'user': user, 'date':date, 'text': text, 'answer': answer}
# df = pd.DataFrame(dict)
# df.to_excel("전처리_원본.xlsx")

# #답변 5개씩만 (+나중에 채팅상담실에서 더 많은 이야기~ 같은 답변 제외하기)
answer1 = []
answer2 = []
answer3 = []
answer4 = []
answer5 = []

for replys in answer:
  length = len(replys)
  for i in range(length):
    if (i == 0): answer1.append(replys[0])
    if (i == 1): answer2.append(replys[1])
    if (i == 2): answer3.append(replys[2])
    if (i == 3): answer4.append(replys[3])
    if (i == 4): answer5.append(replys[4])
  while length < 5:
    if (length == 0): answer1.append("")
    if (length == 1): answer2.append("")
    if (length == 2): answer3.append("")
    if (length == 3): answer4.append("")
    if (length == 4): answer5.append("")
    length += 1

#답변 추천용 데이터셋 생성
dict = {'title': title, 'user': user, 'date':date, 'text': text, 'answer1': answer1,'answer2': answer2,'answer3': answer3,'answer4': answer4,'answer5': answer5}
df = pd.DataFrame(dict)
df.to_excel("답변5개.xlsx")

#korean sentence splitter(https://github.com/likejazz/korean-sentence-splitter) 사용 -> 문장 분리 
!pip install kss
import kss

sentences = []

for t in text:
  for sentence in kss.split_sentences(t):
    sentences.append(sentence);

# 감정 분류 데이터셋 생성
dict = {'Sentence': sentences}
emotion_df = pd.DataFrame(dict)
emotion_df
emotion_df.to_excel("감정_문장별.xlsx")

"""제목 / 고민 / 답변자1 내용 / 답변자2 내용/ 답변자3 내용/답변자4 내용/답변자5 내용"""