# -*- coding: utf-8 -*-
"""preprocess_1388.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_wH5r-mgakEVE349rTY5ei21B8OW9faR
"""

import pandas as pd

from google.colab import drive

# 구글 드라이브에서 데이터 로드
drive.mount('/content/drive', force_remount=True)

data = pd.read_csv("/content/drive/My Drive/Colab Notebooks/crawl.csv")

import re 
def preprocess_text(sentence):
  re_pattern = r'\r'
  new_text = re.sub(re_pattern, '', sentence)
  re_pattern = r'\n'
  new_text = re.sub(re_pattern, '', new_text)
  re_pattern = r'\t'
  new_text = re.sub(re_pattern, '', new_text)
  return new_text


data.iloc[:,0] = data.iloc[:,0].apply(preprocess_text)
data.iloc[:,1] = data.iloc[:,1].apply(preprocess_text)

data = data.set_axis(['고민','답변'], axis=1, inplace=False)
data

pd.set_option('display.max_colwidth',1000)

# 고민 내용 전처리
def pre_text(sentence):
  re_pattern = r'고민상담게시판'
  new_text = re.sub(re_pattern, '', sentence)
  re_pattern = r'제목'
  new_text = re.sub(re_pattern, '', new_text)
  return new_text

data.iloc[:,0] = data.iloc[:,0].apply(pre_text)
data

# 답변 내용 전처리

answer = []
for idx, sentence in enumerate(data['답변']):
  info = sentence.split('작성자 ')
  info.pop(0) #첫 element 삭제
  info2 = []
  if len(info) > 1:
    st = info[0]
    s = info[0]
    for i in range(len(info)-1):
      if (st[3] == info[i+1][3]):
        s+= info[i+1]
      else:
        info2.append(s)
        st = info[i+1]
        s = info[i+1]
    if s != "":
      info2.append(s)
  answer.append(info2)

answer[0]

# 게시글의 답변 개수 보기 
len_list = [0 for i in range(26)]
for idx,x in enumerate(answer):
  len_list[len(x)] += 1

for idx, x in enumerate(len_list):
  print(idx , " " , x)

#확인용 - 지우가
answer = []
for sentence in data['답변']:
  info = sentence.split('작성자')
  info.pop(0) #첫 element 삭제
  answer.append(info)

answer[0]

#answer애서 컴슬러 이름, 시간 지우기 컴슬러P (2015-09-18 01:34:00)
def pre_text(sentence):
  re_pattern = r'고민상담게시판'
  new_text = re.sub(re_pattern, '', sentence)
  re_pattern = r'제목'
  new_text = re.sub(re_pattern, '', new_text)
  return new_text

data.iloc[:,0] = data.iloc[:,0].apply(pre_text)

# 데이터 분리
title = []
user = []
date = []
text = []

for sentence in data['고민']:
  info = sentence.split('작성자',1)
  title.append(info[0])
  info2 = info[1].split('작성일',1)
  user.append(info2[0])
  string = (info2[1])
  date.append(string[:10])
  text.append(string[10:])

dict = {'title': title, 'user': user, 'date':date, 'text': text, 'answer': answer}
df = pd.DataFrame(dict)
df

#korean sentence splitter(https://github.com/likejazz/korean-sentence-splitter) 사용 -> 문장 분리 
!pip install kss
import kss

sentences = []

for t in text:
  for sentence in kss.split_sentences(t):
    sentences.append(sentence);

# 감정 분류 데이터셋 생성
dict = {'Sentence': sentences}
emotion_df = pd.DataFrame(dict)
emotion_df
emotion_df.to_excel("감정_문장별.xlsx")

"""제목 / 고민 / 답변자1 내용 / 답변자2 내용/ 답변자3 내용/답변자4 내용/답변자5 내용"""